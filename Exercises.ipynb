{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise : check the error evolution \n",
    "\n",
    "\n",
    "\n",
    "In one code, generate 100 times:\n",
    "\n",
    "    Normal random trails of 10 elements with variance = 1\n",
    "    Normal random trails of 100 elements with variance = 1\n",
    "    Normal random trails of 1000 elements with variance = 1\n",
    "Evaluate the mean of each realisation and then the standard deviation of the means for each group 100 realisations (1 stdev for 10 elements, one for 100 elements and one for 100 elements)\n",
    "\n",
    "report the results of the 3 tandard deviations in one plot and compare with expected value $1./\\sqrt(N)$ (because each trial is with variance = 1.)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice : Random trial following a given PDF\n",
    "\n",
    "The goal of this exercise is to generate a random trial following a Probabilty Distribution Function (PDF) I give you in the file: \"PDF_double_gauss.txt\".\n",
    "\n",
    "**1)** Read the file \"**PDF_double_gauss.txt**\" (think to take a look to the file befor to know if you need to transpose or not when you use numpy.loadtxt). There 2 arrays : x_arr and pdf_arr. (ie. x and p(x)) \n",
    "\n",
    "**2)** Determine the size of the element dx \n",
    "\n",
    "**3)** Check that the sum pdf_arr * dx is close to 1 (in this case, the pdf is realy a pdf)\n",
    "\n",
    "**4)** Construct the cumulative distribution function (CDF) in an array cumul_arr\n",
    "\n",
    "**5)** plot the PDF and the CDF in two diferent plots\n",
    "\n",
    "**6)** Using uniform random trials and the CDF from **4)**, generate 10000 random trials you will store in an array **myrand_arr**\n",
    "\n",
    "**7)** Plot the normed (sum=1) histogram of your trials using numpy.hist, using 500 bins between. Overplot **pdf_arr**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise : Halo mass with histogram\n",
    "\n",
    "The idea is to read a file with halo of dark matter from a simulation and generate an histogram of the mass distribution in log-log. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Exercise : $\\chi^2$ with covariance matrix\n",
    "\n",
    "This exercise will use most of the stuff presented during the lecture.\n",
    "\n",
    "    read file\n",
    "    create arrays, ndarray, matrix\n",
    "    use loops\n",
    "    generate plots, contours and pcolormesh\n",
    "    \n",
    "\n",
    "I have generate a file with 10 points following a linear law $Y = A*X + B$ where you have to determine **A** and **B**. You will find the best fit value, but also draw the confidence interval (ie contours ) using $\\Delta \\chi^2$ method.\n",
    "\n",
    "### Visualisation of the data\n",
    "\n",
    "**1)** Read the file 'Points_chi2_example_cov.txt' which contain X and Y array (10 points each array)\n",
    "\n",
    "**2)** Read the file 'Covariance_chi2_example_cov.txt' which contain covariance matrix\n",
    "\n",
    "**3)** Plot Y vs X with marker and no line. Do a pcolormesh of the covariance matrix.\n",
    "\n",
    "**4)** Use the diagonal terms of the covariance matrix as the variance of each 10 Y points and draw plot the same plot as in **3)** but with error bars (have to be the square root of the variance ;) )\n",
    "\n",
    "### Prepare to fit\n",
    "\n",
    "**5)** Create 2 arrays, named **A_arr** and **B_arr**, of values spaced by 0.1 between -6 and 4 \n",
    "\n",
    "**6)** Generate a 2D-array, named **chi2_arr**, full of 0. with size (len(A_arr), len(B_arr))\n",
    "\n",
    "**7)** Using a double loop, evluate at each point of the **chi2_arr[ii,jj]** the value of the $\\chi^2 = \\frac{1}{2} \\vec{V}^T Cov^{-1} \\vec{V}$  where $\\vec{V}$ is the array of 10 elements (A_rr[ii] * X + B_arr[jj] - Y)\n",
    "\n",
    "**8)** Find the best fit parameters ($A_{best}, B_{best}$) which correspond to the minimum of **chi2_arr**\n",
    "\n",
    "**9)** Plot one more time X,Y with errorbar() and add the best fit model\n",
    "\n",
    "### Confidence contours\n",
    "\n",
    "One time you have found the best fit, you want to obtain obtain the confidence region. To do that, you have to considerate the $\\Delta \\chi^2 = \\chi^2 - min(\\chi^2)$ and consider the values for 2 parameters for $1,2,3\\sigma$. \n",
    "\n",
    "**10)** Generate a new 2D array, named **Delta_chi2_arr**, equal to **chi2_arr**-np.min(chi2_arr)\n",
    "\n",
    "**11)** Do a pcolormesh of this new array and add a marker at the best parameters value position\n",
    "\n",
    "**12)** Using the values for 2 parameters for $1,2,3\\sigma$, generate the contour plot for these 3 values. The real values I used to generate the data points are A_real = 2.7 and B_real = -2.3. Add a marker on the contour plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
